
def format_string(string):
    formatted = ""

    for line in string.split("\n"):
        if line.startswith("# "):
            formatted += f"## {line[2:]}\n"
        elif line.startswith("## "):
            formatted += f"### {line[3:]}\n"
        elif line.startswith("### "):
            formatted += f"#### {line[4:]}\n"
        else:
            formatted += f"{line}\n"

    with open("readable.md", "w", encoding="utf-8") as f:
        f.write(formatted)

    print("Formatted string written to readable.md")
    return formatted


def extract_evaluations(text):
    """
    Extracts evaluation sections from text that start with 'EVALUATION:' 
    and continue until an empty line is encountered.
    """
    evaluations = []
    lines = text.split('\n')

    i = 0
    while i < len(lines):
        line = lines[i].strip()
        
        # Check if line starts with "EVALUATION:"
        if line.startswith("EVALUATION:"):
            evaluation_lines = [line]
            i += 1
            
            # Continue collecting lines until empty line or end of text
            while i < len(lines):
                current_line = lines[i]
                
                # Stop if we hit an empty line
                if current_line.strip() == "":
                    break
                    
                evaluation_lines.append(current_line)
                i += 1
            
            # Join the evaluation lines and add to results
            evaluations.append('\n'.join(evaluation_lines))
        
        i += 1

    with open("evaluations.md", "w", encoding="utf-8") as f:
        for evaluation in evaluations:
            f.write(f"{evaluation}\n\n")

    print("Evaluations extracted and written to evaluations.md")

    return evaluations


# string = str(input("Enter the string to format:\n"))
string = """


{
    "status": {
        "error": true,
        "type": "BadSyntax",
        "message": "at line 1 of <>:\nBad syntax (expected directive or statement) at ^ in:\n\"b''^b'flowchart TD\\r\\n    Start([Start]) --> A[Extract required onto'...\"",
        "traceback": "<traceback object at 0x00000214B8293040>"
    },
    "dataset": "LLM_eval/datasets\\fiware_v1_hotel",
    "JEN": "LLM_eval/datasets\\fiware_v1_hotel\\fiware_entities_2rooms.json",
    "JEX": "LLM_eval/datasets\\fiware_v1_hotel\\fiware_example.json",
    "ontology": "LLM_eval/ontologies\\Brick.ttl",
    "api_spec": "LLM_eval/API_specs\\FIWAR_ngsiV2_API_spec.json",
    "scenarios": [
        "II"
    ],
    "scenario_II_(0)": {
        "step_name": "scenario_II_(0)",
        "prompt": "\n        <input> \n        # file: JSON Example file\n            description:\n                The JSON Example file is a sample data file that contains all unique entity types of the JSON Entities file, a response of a GET request to the API of an IoT platform.\n                It represents the data structure of the JSON Entities file, but with only one instance of each entity type.\n            content:\n                <data>[\n  {\n    \"id\": \"Hotel:example_hotel\",\n    \"type\": \"Hotel\",\n    \"name\": {\n      \"type\": \"Text\",\n      \"value\": \"example_hotel\",\n      \"metadata\": {}\n    }\n  },\n  {\n    \"id\": \"AmbientTemperatureSensor\",\n    \"type\": \"AmbientTemperatureSensor\", \n    \"temperatureAmb\": {\n      \"type\": \"Number\",\n      \"value\": 0.0,\n      \"metadata\": {}\n    },\n    \"hasLocation\": {\n      \"type\": \"Relationship\",\n      \"value\": \"Hotel:example_hotel\",\n      \"metadata\": {}\n    }\n  },\n  {\n    \"id\": \"HotelRoom:example_room\",\n    \"type\": \"HotelRoom\",\n    \"hasLocation\": {\n      \"type\": \"Text\",\n      \"value\": \"Hotel:fiware\",\n      \"metadata\": {}\n    },\n    \"name\": {\n      \"type\": \"Text\",\n      \"value\": \"example_room\",\n      \"metadata\": {}\n    }\n  },\n  {\n    \"id\": \"TemperatureSensor:example_room\",\n    \"type\": \"TemperatureSensor\",\n    \"hasLocation\": {\n      \"type\": \"Relationship\",\n      \"value\": \"HotelRoom:example_room\",\n      \"metadata\": {}\n    },\n    \"temperature\": {\n      \"type\": \"Number\",\n      \"value\": 0.0,\n      \"metadata\": {}\n    }\n  },\n  {\n    \"id\": \"CO2Sensor:example_room\",\n    \"type\": \"CO2Sensor\",\n    \"co2\": {\n      \"type\": \"Number\",\n      \"value\": 0.0,\n      \"metadata\": {}\n    },\n    \"hasLocation\": {\n      \"type\": \"Relationship\",\n      \"value\": \"HotelRoom:example_room\",\n      \"metadata\": {}\n    }\n  },\n  {\n    \"id\": \"PresenceSensor:example_room\",\n    \"type\": \"PresenceSensor\",\n    \"hasLocation\": {\n      \"type\": \"Relationship\",\n      \"value\": \"HotelRoom:example_room\",\n      \"metadata\": {}\n    },\n    \"pir\": {\n      \"type\": \"Number\",\n      \"value\": 0.0,\n      \"metadata\": {}\n    }\n  },\n  {\n    \"id\": \"FreshAirVentilation:example_room\",\n    \"type\": \"FreshAirVentilation\",\n    \"airFlowSetpoint\": {\n      \"type\": \"Number\",\n      \"value\": 0.0,\n      \"metadata\": {}\n    },\n    \"hasLocation\": {\n      \"type\": \"Relationship\",\n      \"value\": \"HotelRoom:example_room\",\n      \"metadata\": {}\n    }\n  },\n  {\n    \"id\": \"RadiatorThermostat:example_room\",\n    \"type\": \"RadiatorThermostat\",\n    \"hasLocation\": {\n      \"type\": \"Relationship\",\n      \"value\": \"HotelRoom:example_room\",\n      \"metadata\": {}\n    },\n    \"temperatureSetpoint\": {\n      \"type\": \"Number\",\n      \"value\": 0.0,\n      \"metadata\": {}\n    }\n  },\n  {\n    \"id\": \"CoolingCoil:example_room\",\n    \"type\": \"CoolingCoil\",\n    \"fanSpeed\": {\n      \"type\": \"Number\",\n      \"value\": 0.0,\n      \"metadata\": {}\n    },\n    \"hasLocation\": {\n      \"type\": \"Relationship\",\n      \"value\": \"HotelRoom:example_room\",\n      \"metadata\": {}\n    }\n  }\n]</data>\n        </input>\n        <context>\n        # Results of Preprocessing of the JSON file: \n{'api_endpoint': 'https://fiware.eonerc.rwth-aachen.de/v2/entities/{entityId}/attrs/{attrName}/value', 'numerical_properties': ['temperatureAmb', 'temperature', 'co2', 'pir', 'airFlowSetpoint', 'temperatureSetpoint', 'fanSpeed'], 'relational_properties': ['hasLocation', 'name'], 'entity_mappings': {'Hotel': 'rec:Building', 'AmbientTemperatureSensor': 'brick:Air_Temperature_Sensor', 'HotelRoom': 'rec:Bedroom', 'TemperatureSensor': 'brick:Temperature_Sensor', 'CO2Sensor': 'brick:CO2_Sensor', 'PresenceSensor': 'brick:Occupancy_Sensor', 'FreshAirVentilation': 'brick:Ventilation_Air_System', 'RadiatorThermostat': 'brick:HVAC_Equipment', 'CoolingCoil': 'brick:Cooling_Coil'}, 'relational_property_mappings': {'hasLocation': 'brick:hasLocation', 'name': 'bacnet:object-name'}, 'extra_nodes': {'properties_requiring_extra_nodes': ['airFlowSetpoint', 'temperatureSetpoint', 'fanSpeed'], 'extra_node_names': ['AirFlowSetpoint', 'TemperatureSetpoint', 'FanSpeedSetpoint'], 'extra_node_mappings': {'AirFlowSetpoint': 'brick:Air_Flow_Setpoint', 'TemperatureSetpoint': 'brick:Temperature_Setpoint', 'FanSpeedSetpoint': 'brick:Speed_Setpoint'}}}\n        \n        # RML Mapping File \n        The RML mapping file is used to generate the RDF knowledge graph from the JSON Entities data.\n\n        The knowledge graph looks like this: \n\n        # Knowledge Graph \n        The knowledge graph is a structured representation of the building's systematic components, including rooms, ventilation devices, sensors, and their relationships. \n        It is built from the provided JSON entities file of a GET request to a specific IoT platform.\n\n        <constraints>MOST IMPORTANT: RDF should follow a valid turtle syntax!</constraints>\n\n        <data>\nOntology prefixes:\n@prefix bacnet: <http://data.ashrae.org/bacnet/2020#> .\n@prefix brick: <https://brickschema.org/schema/Brick#> .\n@prefix bsh: <https://brickschema.org/schema/BrickShape#> .\n@prefix dcterms: <http://purl.org/dc/terms/> .\n@prefix owl: <http://www.w3.org/2002/07/owl#> .\n@prefix qudt: <http://qudt.org/schema/qudt/> .\n@prefix qudtqk: <http://qudt.org/vocab/quantitykind/> .\n@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n@prefix rec: <https://w3id.org/rec#> .\n@prefix ref: <https://brickschema.org/schema/Brick/ref#> .\n@prefix s223: <http://data.ashrae.org/standard223#> .\n@prefix sdo: <http://schema.org/> .\n@prefix sh: <http://www.w3.org/ns/shacl#> .\n@prefix skos: <http://www.w3.org/2004/02/skos/core#> .\n@prefix sosa: <http://www.w3.org/ns/sosa/> .\n@prefix tag: <https://brickschema.org/schema/BrickTag#> .\n@prefix unit: <http://qudt.org/vocab/unit/> .\n@prefix vcard: <http://www.w3.org/2006/vcard/ns#> .\n@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n</data>\n        <rules>\n# Knowledge Graph Rules\nFor the RDF graph to properly support configuration generation, the following elements are essential:\n\nRule 1: Entity Declaration\nAlways: Every IoT entity and each Extra Node must be declared with:\n- A unique URI following the pattern <http://example.com/{{ENTITY_TYPE}}/{{ID}}>\n- A type classification using a {{ONTOLOGY_CLASS}}\n\nRule 2: Ontology Prefixes\nAlways: The knowledge graph must begin with:\n- {{ONTOLOGY_PREFIXES}} declaration\n- Standard RDF prefix: @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n- Do not add prefixes for the API endpoint, but use the full URI in angle brackets.\n\nRule 3: Numerical Data Source\nIf: An entity provides or exposes numerical data (accessible by API endpoint) \nThen: Add the property rdf:value <{{API_ENDPOINT_URL}}>\n\nRule 4: Relational Connections\nIf: An entity has relationships or connections to other entities \nThen: Add one or more properties using {{ONTOLOGY_PROPERTY}} <http://example.com/{{ENTITY_TYPE}}/{{ID}}>\n- System hierarchies must be properly represented\n- The datamodel must be represented correctly\n- Devices must be properly connected to their locations (e.g., sensors to rooms)\n\n</rules>\n        \n\n        <constraints>MOST IMPORTANT: RML should follow a valid turtle syntax!</constraints>\n        <data>\nOntology prefixes:\n@prefix bacnet: <http://data.ashrae.org/bacnet/2020#> .\n@prefix brick: <https://brickschema.org/schema/Brick#> .\n@prefix bsh: <https://brickschema.org/schema/BrickShape#> .\n@prefix dcterms: <http://purl.org/dc/terms/> .\n@prefix owl: <http://www.w3.org/2002/07/owl#> .\n@prefix qudt: <http://qudt.org/schema/qudt/> .\n@prefix qudtqk: <http://qudt.org/vocab/quantitykind/> .\n@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n@prefix rec: <https://w3id.org/rec#> .\n@prefix ref: <https://brickschema.org/schema/Brick/ref#> .\n@prefix s223: <http://data.ashrae.org/standard223#> .\n@prefix sdo: <http://schema.org/> .\n@prefix sh: <http://www.w3.org/ns/shacl#> .\n@prefix skos: <http://www.w3.org/2004/02/skos/core#> .\n@prefix sosa: <http://www.w3.org/ns/sosa/> .\n@prefix tag: <https://brickschema.org/schema/BrickTag#> .\n@prefix unit: <http://qudt.org/vocab/unit/> .\n@prefix vcard: <http://www.w3.org/2006/vcard/ns#> .\n@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n</data>\n        <template>\n{ONTOLOGY_PREFIXES}\n@prefix ex: <http://example.com#> .\n@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n\n# This template defines reusable patterns for mapping IoT entities to RDF using RML \n# Terms in uppercase and curly braces {} are placeholders to be replaced with terms\n\n# Mapping for {ENTITY_TYPE}\nex:Mapping{ENTITY_TYPE}\n    a rr:TriplesMap ;\n    rml:logicalSource [\n        rml:source \"placeholder.json\" ;\n        rml:referenceFormulation ql:JSONPath ;\n        rml:iterator '$[?(@.type==\"{ENTITY_TYPE}\")]' ;\n    ] ;\n    rr:subjectMap [\n        rr:template \"http://example.com/{ENTITY_TYPE}/{id}\" ;\n        rr:class {ONTOLOGY_CLASS} ;\n    ] ;\n    \n    # BUILDING BLOCK: Non-numerical Relationships between Entities\n    rr:predicateObjectMap [\n        rr:predicate {ONTOLOGY_ROPERTY} ;\n        rr:objectMap [\n            rr:parentTriplesMap ex:Mapping{ENTITY_TYPE} ;\n            rr:joinCondition [\n                rr:child \"{CHILD_JOIN_FIELD}\" ;\n                rr:parent \"{PARENT_JOIN_FIELD}\" ;\n            ] ;\n        ] ;\n    ] ;\n\n    # BUILDING BLOCK: Numerical Relationships\n    rr:predicateObjectMap [\n        rr:predicate rdf:value ;\n        rr:objectMap [\n            rr:template \"{API_ENDPOINT_URL}\" ;\n        ] ;\n    ] ;\n\n</template>\n        \n        </context>\n\n        <instructions>\n        Generate the RML mapping file from the provided JSON Example file needed for generating the knowledge graph based on the template.\n        For every entity in the JSON Example file and for every Extra Node, create a corresponding entity in the RML mapping file.\n        For each RML entity, choose a suitable block from the template and fill out the placeholders with the results of Preprocessing of the JSON file.\n        Do not replace the '{id}' but all other placeholders that are in curly brackets AND in uppercase.\n        For connecting extra nodes to the parent entities, choose a previously mapped ontology property for relations.\n        For every prefix you use in the document, there need to be a corresponding decalaration of the prefix choosen from the Ontology Prefixes input.\n \n        Do not use any other information to fill out the RML mapping file.\n        If you have any doubts, fill in a marker at the point and add a comment with your question.\n        </instructions>\n\n        <output> Return the RML Mapping file in Turtle format. </output>\n        \n        <context>\n        \n        # Bloom's Taxonomy Categories:\n        1. Knowledge: Remembering or retrieving previously learned material. Examples of verbs that relate to this function are: know identify relate list  define recall memorize repeat  record name recognize acquire\n        2. Comprehension: The ability to grasp or construct meaning from material. Examples of verbs that relate to this function are: restate locate report recognize explain express  identify discuss describe discuss review infer  illustrate interpret draw represent differentiate conclude\n        3. Application: The ability to use learned material, or to implement material in new and concrete situations. Examples of verbs that relate to this function are: apply relate develop translate use operate  organize employ restructure interpret demonstrate illustrate  practice calculate show exhibi\n        4. Analysis: The ability to break down or distinguish the parts of material into its components so that its organizational structure may be better understood. Examples of verbs that relate to this function are:  analyze compare probe inquire examine contrast categorize  differentiate contrast investigate detect survey classify deduce  experiment scrutinize discover inspect dissect discriminate separate\n        5. Synthesis: The ability to put parts together to form a coherent or unique new whole. Examples of verbs that relate to this function are: compose produce design assemble create prepare predict modify tell  plan invent formulate collect set up generalize document combine relate  propose develop arrange construct organize originate derive write propose\n        6. Evaluation: The ability to judge, check, and even critique the value of material for a given purpose. Examples of verbs that relate to this function are: judge assess compare evaluate conclude measure deduce  argue decide choose rate select estimate  validate consider appraise value criticize infer\n        \n        \n        # Knowledge Dimensions:\n        - Factual Knowledge: is knowledge that is basic to specific disciplines. This dimension refers to essential facts, terminology, details or elements students must know or be familiar with in order to understand a discipline or solve a problem in it.  \n        - Conceptual Knowledge: is knowledge of classifications, principles, generalizations, theories, models, or structures pertinent to a particular disciplinary area.  \n        - Procedural Knowledge: refers to information or knowledge that helps students to do something specific to a discipline, subject, or area of study. It also refers to methods of inquiry, very specific or finite skills, algorithms, techniques, and particular methodologies.  \n        - Metacognitive Knowledge: is the awareness of one\u2019s own cognition and particular cognitive processes. It is strategic or reflective knowledge about how to go about solving problems, cognitive tasks, to include contextual and conditional knowledge and knowledge of self.\n        \n        \n        # Quantity \n        In the step description, consisting of a verb that describes the action and the targets of the action, the quantity is the count of all targets of the action.\n        **Target Identification Rule**: The targets should be the actual objects being processed, created, or manipulated by the action, not the cothentainer or context.\n        Examples:\n        - \"parsing 5 JSON objects\": quantity = 5 (cognitive operation: \"parse\", target: \"JSON objects\", not the file containing them)\n        - \"applying a rule to 10 data points\": quantity = 10 (cognitive operation: \"apply validation rule\", target: \"data points\", not the rule)\n        Quantity should enable meaningful comparison across different granularity levels.\n        \n        # Human Effort Index\n        Evaluation of the effort of a qualified expert required to complete this step.\n        Based on own evaluation considering the following factors:\n        - The amount of cognitive load required to complete this step\n        - The amount of time needed to complete this step\n        (from 1 to 100, where 1 is very easy and 100 is very hard)\n        Provide a short reasoning for the score.\n        It is crucial to provide a score that is comparable to other steps in the task.\n        The proportion of the score between two steps should reflect the proportion of the effort required to complete the steps.\n        </context>\n\n        <instructions>\n        Do the task step by step with maximum consistency and precision.\n        I need a complete step-by-step execution of the task, where each step is fully printed out, even if repetitive, for future analysis and evaluation.\n\n        ### CRITICAL STEP DEFINITION RULES\n        Each step must satisfy ALL of these criteria:\n        - **Single Action**: Performs exactly one distinct cognitive operation\n        - **Single Bloom Level**: Can be classified with exactly one Bloom's Taxonomy category\n        - **Single Output**: Produces exactly one concrete, measurable result\n        - **Atomic**: Cannot be meaningfully subdivided while maintaining the same cognitive operation\n        - **Isolated**: Can be completed without simultaneous work on other steps\n        - **Deterministic**: Same input always produces same type of output\n        - A step is not a decision what to do next\n        \n        ### STEP VALIDATION CHECKLIST\n        Before finalizing any step, verify:\n        1. Can you identify exactly one primary verb that describes the action?\n        2. Does the step require only one type of cognitive process?\n        3. If you removed any part of this step, would the remaining part still be meaningful?\n        4. Can you complete this step without starting the next one?\n\n        If any answer is \"no\", subdivide the step further.\n\n        \n        ### FLOWCHART NAVIGATION RULES\n        - Each step must correspond to exactly one node in the flowchart.\n        - Not every flowchart node must be a step.\n        - Decision diamonds are not steps, but only used to decide which step to take next.\n        - Decision diamonds can only be referenced in the \"NEXT\" section of a step.\n\n\n        ### EXECUTION PROTOCOL\n\n        #### Phase 1: Task Analysis and Flowchart Creation\n        1. Analyze the task complete requirements, instructions and constraints.\n        2. Identify all process nodes and possible decision points and alternative paths.\n            - If a node has multiple possible next steps, use a decision diamond to represent the decision point.\n            - If a node may not be executed every time, use a decision diamond to be able to decide if the node is executed or not (e. g. because of conditional rules).\n        3. Create a flowchart to visualize the conditional task structure.\n        4. Estimate the number of steps needed to complete the task.\n            - Consider the flowchart process nodes and decision points on how to process the input data\n            - Consider the number of times to loop the flowchart over the input data\n\n            \n        #### Phase 2: Step-by-Step Execution\n        Remember: Execute the task following the flowchart process nodes and decision points, repeating the steps with the input data as needed.\n        Process exactly ONE step at a time following this format: \n\n        STEP [N]: [verb (optionally plus descriptive noun) that describes the step action] [quantity] [the targets of the action]\n        - flowchart_node: [exact node name from flowchart]\n        - context: [explicit information needed for this step only]\n\n        EXECUTING:\n        [Perform the actual work - show code, calculations, analysis, etc.]\n\n        VALIDATION:\n        - single_bloom_check: [confirm if this step uses only one Bloom level]\n        - subdivision_check: [confirm if this cannot be meaningfully subdivided]\n        - step_validation_checklist: [confirm if all validation criteria are met]\n\n        EVALUATION:\n        - bloom: [single level] - [specific objective in max 7 words]\n        - dim: [single Knowledge Dimension]\n        - quantity: [the count of the noun that describes the target of the action]\n        - human_effort: [1-100 score] - [brief reasoning]\n\n        NEXT: STEP [N+1]: [Next Action Description]\n        [if applicable, decide next step based on flowchart]\n        - decision_point: [if applicable, specify the decision point]\n        - next_flowchart_node: [if applicable, specify the next node in flowchart]\n\n\n\n        #### Phase 3: Consistency Verification\n        After completing all steps, verify:\n        - All steps are represented in flowchart process nodes\n        - No steps combine multiple Bloom levels\n        - Similar cognitive operations have consistent granularity\n        - Quantity measurements are meaningful for comparison\n\n        ### ERROR PREVENTION RULES\n        - **Multi-Bloom Detection**: If you find yourself using \"and\" or \"then\" in a step description, subdivide it\n        - **Multiple Tasks**: If you find multiple tasks in the same step, subdivide them into separate steps\n        - **Granularity Consistency**: Steps handling similar data types should have similar granularity\n        - **Missing Intermediate Steps**: If there's a logical gap between steps, add the missing step\n        - Does the number of steps match the estimated number of steps needed to complete the task?\n\n        </instructions>\n\n        <output>\n        ### OUTPUT FORMAT\n        Output exactly in this order:\n\n        <flowchart>\n        [Flowchart in mermaid syntax showing the process nodes and decision points]\n        </flowchart>\n\n        <estimation>\n        [Estimated number of times to loop the flowchart over the input data]\n        </estimation>\n\n        <steps>\n        [Complete step-by-step execution following the format above]\n        [Every single step must be fully printed out, even if repetitive - no summarization or skipping]\n        </steps>\n\n        <output>\n        [Final deliverable result of the task, e.g. JSON, RDF, etc.]\n        [The output can only be a composition of the execution results of the steps]\n        </output>\n\n        <verification>\n        Total Steps: [count]\n        Flowchart Compliance: [yes/no - if all steps are represented in flowchart process nodes]\n        Bloom Consistency: [yes/no - if all steps use only one Bloom level]\n        Granularity Check: [yes/no - if all steps have consistent abstraction level]\n        </verification>\n\n        ",
        "thinking": "Let me analyze this task step by step:\n\n1. I need to generate an RML mapping file from the provided JSON Example file\n2. The RML mapping file will be used to generate a knowledge graph\n3. I have preprocessing results that provide entity mappings, property mappings, and extra nodes\n4. I need to follow the template structure and rules provided\n\nLet me break down the input data:\n\nFrom the JSON Example file, I have these entities:\n- Hotel:example_hotel (type: Hotel)\n- AmbientTemperatureSensor\n- HotelRoom:example_room (type: HotelRoom) \n- TemperatureSensor:example_room (type: TemperatureSensor)\n- CO2Sensor:example_room (type: CO2Sensor)\n- PresenceSensor:example_room (type: PresenceSensor)\n- FreshAirVentilation:example_room (type: FreshAirVentilation)\n- RadiatorThermostat:example_room (type: RadiatorThermostat)\n- CoolingCoil:example_room (type: CoolingCoil)\n\nFrom preprocessing results:\n- API endpoint: 'https://fiware.eonerc.rwth-aachen.de/v2/entities/{entityId}/attrs/{attrName}/value'\n- Numerical properties: ['temperatureAmb', 'temperature', 'co2', 'pir', 'airFlowSetpoint', 'temperatureSetpoint', 'fanSpeed']\n- Relational properties: ['hasLocation', 'name']\n- Entity mappings: {'Hotel': 'rec:Building', 'AmbientTemperatureSensor': 'brick:Air_Temperature_Sensor', 'HotelRoom': 'rec:Bedroom', 'TemperatureSensor': 'brick:Temperature_Sensor', 'CO2Sensor': 'brick:CO2_Sensor', 'PresenceSensor': 'brick:Occupancy_Sensor', 'FreshAirVentilation': 'brick:Ventilation_Air_System', 'RadiatorThermostat': 'brick:HVAC_Equipment', 'CoolingCoil': 'brick:Cooling_Coil'}\n\n\n- Relational property mappings: {'hasLocation': 'brick:hasLocation', 'name': 'bacnet:object-name'}\n- Extra nodes: properties requiring extra nodes: ['airFlowSetpoint', 'temperatureSetpoint', 'fanSpeed'], with mappings to {'AirFlowSetpoint': 'brick:Air_Flow_Setpoint', 'TemperatureSetpoint': 'brick:Temperature_Setpoint', 'FanSpeedSetpoint': 'brick:Speed_Setpoint'}\n\nI'll identify the key mapping details for creating the RML structure. The preprocessing results provide crucial ontological mappings and property transformations. I'll focus on translating these entities and properties into a structured knowledge graph representation using the specified ontology prefixes and API endpoint.\n\nThe mapping involves converting specific sensor and room entities to their corresponding ontological classes, with careful attention to numerical and relational properties that require special handling.\n\nI anticipate approximately 14 distinct transformation steps, encompassing prefix extraction, base structure creation, entity mapping, extra node connections, and final syntax validation. This systematic approach ensures comprehensive and accurate knowledge graph generation.",
        "response": "<flowchart>\n```mermaid\nflowchart TD\n    Start([Start]) --> A[Extract required ontology prefixes]\n    A --> B[Create base RML structure with prefixes]\n    B --> C[Initialize entity counter]\n    C --> D{More entities to process?}\n    D -->|Yes| E[Select next entity from JSON]\n    E --> F[Create TriplesMap for entity]\n    F --> G[Add subject mapping with ontology class]\n    G --> H{Entity has numerical properties?}\n    H -->|Yes| I[Add numerical property mappings with API endpoint]\n    H -->|No| J{Entity has relational properties?}\n    I --> J\n    J -->|Yes| K[Add relational property mappings]\n    J -->|No| L[Increment entity counter]\n    K --> L\n    L --> D\n    D -->|No| M[Initialize extra node counter]\n    M --> N{More extra nodes to process?}\n    N -->|Yes| O[Select next extra node]\n    O --> P[Create TriplesMap for extra node]\n    P --> Q[Add subject mapping for extra node]\n    Q --> R[Add connection to parent entity]\n    R --> S[Increment extra node counter]\n    S --> N\n    N -->|No| T[Validate RML syntax]\n    T --> End([End])\n```\n</flowchart>\n\n<estimation>\nBased on the flowchart, I need to process:\n- 9 entities from the JSON file (each requiring 3-5 sub-steps)\n- 3 extra nodes (each requiring 3 sub-steps)\n- Plus initialization and validation steps\nTotal estimated steps: approximately 20-25 steps\n</estimation>\n\n<steps>\n\nSTEP 1: extract 10 required ontology prefixes\n- flowchart_node: Extract required ontology prefixes\n- context: Need to identify which ontology prefixes are used in the preprocessing results for entity mappings and relational property mappings\n\nEXECUTING:\nLooking at the preprocessing results:\n- Entity mappings use: rec: (rec:Building, rec:Bedroom), brick: (multiple classes)\n- Relational property mappings use: brick: (brick:hasLocation), bacnet: (bacnet:object-name)\n- Also need: rdf: (for rdf:value), rr: and rml: (for RML syntax), ql: (for JSONPath)\n\nRequired prefixes:\n- @prefix rec: <https://w3id.org/rec#>\n- @prefix brick: <https://brickschema.org/schema/Brick#>\n- @prefix bacnet: <http://data.ashrae.org/bacnet/2020#>\n- @prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n- @prefix rr: <http://www.w3.org/ns/r2rml#>\n- @prefix rml: <http://semweb.mmlab.be/ns/rml#>\n- @prefix ql: <http://semweb.mmlab.be/ns/ql#>\n\nVALIDATION:\n- single_bloom_check: Knowledge - recalling which prefixes are needed based on mappings\n- subdivision_check: Cannot be subdivided - this is a single extraction operation\n- step_validation_checklist: Single action (extract), single output (list of prefixes), atomic\n\nEVALUATION:\n- bloom: Knowledge - recall required ontology prefixes\n- dim: Factual Knowledge\n- quantity: 10\n- human_effort: 15 - Simple recall task but requires careful attention to all used prefixes\n\n",
        "performance": {
            "time": {
                "latency": 34.19,
                "tpot": 0.0196,
                "ttft": null
            },
            "tokens": {
                "input_tokens": 6394,
                "cache_creation_input_tokens": 0,
                "cache_read_input_tokens": 0,
                "output_tokens": 1745,
                "service_tier": "standard"
            }
        },
        "sub_steps": null
    }
}

"""


format_string(string)
evaluations = extract_evaluations(string)
